package agent

import (
	"context"
	"encoding/json"
	"fmt"
	"net/http"
	"strings"

	"pomelo-wishlist/internal/domain"

	"github.com/sashabaranov/go-openai"
)

// Agent interface for different intervention moments
type Agent interface {
	IntakeIntervention(ctx context.Context, req IntakeRequest) (*IntakeResponse, error)
	EstimationIntervention(ctx context.Context, req EstimationRequest) (*EstimationResponse, error)
	ScoringIntervention(ctx context.Context, req ScoringRequest) (*ScoringResponse, error)
}

// AgentService implements the Agent interface
type AgentService struct {
	scoringService ScoringService
	openaiClient   *openai.Client
}

func NewAgentService(scoringService ScoringService) *AgentService {
	// Use Cloudflare AI Gateway with custom HTTP client
	httpClient := &http.Client{
		Transport: &CustomTransport{},
	}

	config := openai.DefaultConfig("dummy-key") // Cloudflare gateway doesn't use this
	config.BaseURL = "https://gateway.ai.cloudflare.com/v1/bec721af5515c5801c5177906b6bc3b9/pomethon_wow/openai/v1"
	config.HTTPClient = httpClient

	client := openai.NewClientWithConfig(config)

	return &AgentService{
		scoringService: scoringService,
		openaiClient:   client,
	}
}

// Custom transport to add Cloudflare headers
type CustomTransport struct{}

func (t *CustomTransport) RoundTrip(req *http.Request) (*http.Response, error) {
	req.Header.Set("cf-aig-authorization", "Bearer 7axChTS1U9x8hdZ3r4L36ipj6FRjuHDDq4Tifi_w")
	// Remove the OpenAI Authorization header since we use cf-aig-authorization
	req.Header.Del("Authorization")
	return http.DefaultTransport.RoundTrip(req)
}

// Intake intervention types and structures
type IntakeRequest struct {
	UserInput  string                 `json:"user_input"`
	Initiative *domain.Initiative     `json:"initiative,omitempty"`
	Context    map[string]interface{} `json:"context,omitempty"`
	Step       string                 `json:"step"` // "start", "continue", "validate"
}

type IntakeResponse struct {
	Questions           []Question             `json:"questions,omitempty"`
	Suggestions         []domain.Suggestion    `json:"suggestions,omitempty"`
	ExecutiveSummary    string                 `json:"executive_summary,omitempty"`
	ConfirmationSummary string                 `json:"confirmation_summary,omitempty"`
	Options             []ConfirmationOption   `json:"options,omitempty"`
	NextStep            string                 `json:"next_step"`
	IsComplete          bool                   `json:"is_complete"`
	ExtractedData       map[string]interface{} `json:"extracted_data,omitempty"`
	AwaitingConfirmation bool                   `json:"awaiting_confirmation,omitempty"`
}

type Question struct {
	ID       string   `json:"id"`
	Text     string   `json:"text"`
	Type     string   `json:"type"` // "text", "select", "multiselect", "boolean"
	Options  []string `json:"options,omitempty"`
	Required bool     `json:"required"`
}

type ConfirmationOption struct {
	ID          string `json:"id"`
	Text        string `json:"text"`
	Description string `json:"description"`
}

// Estimation intervention types
type EstimationRequest struct {
	Initiative *domain.Initiative     `json:"initiative"`
	UserInput  string                 `json:"user_input"`
	Context    map[string]interface{} `json:"context,omitempty"`
	Step       string                 `json:"step"`
}

type EstimationResponse struct {
	Questions   []Question                  `json:"questions,omitempty"`
	Suggestions []domain.Suggestion         `json:"suggestions,omitempty"`
	Estimation  *domain.TechnicalEstimation `json:"estimation,omitempty"`
	NextStep    string                      `json:"next_step"`
	IsComplete  bool                        `json:"is_complete"`
}

// Scoring intervention types
type ScoringRequest struct {
	Initiative *domain.Initiative `json:"initiative"`
}

type ScoringResponse struct {
	ScoreBreakdown *domain.ScoreBreakdown `json:"score_breakdown"`
	Suggestions    []domain.Suggestion    `json:"suggestions,omitempty"`
}

// Helper method to call OpenAI through Cloudflare Gateway
func (a *AgentService) callOpenAI(ctx context.Context, systemPrompt, userPrompt string) (string, error) {
	if a.openaiClient == nil {
		return "Mock response: Client not configured", nil
	}

	resp, err := a.openaiClient.CreateChatCompletion(ctx, openai.ChatCompletionRequest{
		Model: "gpt-4.1-nano", // Cloudflare model
		Messages: []openai.ChatCompletionMessage{
			{
				Role:    openai.ChatMessageRoleSystem,
				Content: systemPrompt,
			},
			{
				Role:    openai.ChatMessageRoleUser,
				Content: userPrompt,
			},
		},
		MaxTokens:   1500,
		Temperature: 0.7,
	})

	if err != nil {
		return "", fmt.Errorf("Cloudflare AI Gateway error: %w", err)
	}

	if len(resp.Choices) == 0 {
		return "", fmt.Errorf("no response from AI")
	}

	return resp.Choices[0].Message.Content, nil
}

// Intake intervention implementation
func (a *AgentService) IntakeIntervention(ctx context.Context, req IntakeRequest) (*IntakeResponse, error) {
	switch req.Step {
	case "start":
		return a.startIntake(ctx, req)
	case "continue":
		return a.continueIntake(ctx, req)
	case "validate":
		return a.validateIntake(ctx, req)
	default:
		return nil, fmt.Errorf("unknown intake step: %s", req.Step)
	}
}

func (a *AgentService) startIntake(ctx context.Context, req IntakeRequest) (*IntakeResponse, error) {
	systemPrompt := `Eres un asistente especializado en ayudar a crear iniciativas de negocio. Tu trabajo es generar preguntas inteligentes y contextuales basadas en lo que el usuario quiere crear.

IMPORTANTE: Responde SOLO con JSON v√°lido siguiendo este formato exacto:
{
  "questions": [
    {
      "id": "unique_id",
      "text": "Pregunta en espa√±ol",
      "type": "text|select|multiselect|boolean",
      "options": ["opci√≥n1", "opci√≥n2"],
      "required": true|false
    }
  ],
  "next_step": "continue",
  "is_complete": false
}

Categor√≠as disponibles: regulatory, risk, performance, value_prop, new_product
Pa√≠ses disponibles: brazil, mexico, argentina, colombia, chile, peru
Tipos de cliente: top_issuer, major, medium, small, startup

Genera 2-4 preguntas relevantes y espec√≠ficas basadas en el contexto del usuario.`

	userPrompt := fmt.Sprintf("El usuario quiere crear una iniciativa: '%s'. Genera las primeras preguntas para entender mejor su propuesta.", req.UserInput)

	response, err := a.callOpenAI(ctx, systemPrompt, userPrompt)
	if err != nil {
		return nil, fmt.Errorf("error calling OpenAI: %w", err)
	}

	// Parse JSON response
	var intakeResponse IntakeResponse
	if err := json.Unmarshal([]byte(response), &intakeResponse); err != nil {
		// Fallback to hardcoded questions if JSON parsing fails
		return &IntakeResponse{
			Questions: []Question{
				{ID: "problem_description", Text: "¬øCu√°l es el problema que resuelve esta iniciativa?", Type: "text", Required: true},
				{ID: "category", Text: "¬øEn qu√© categor√≠a la clasificar√≠as?", Type: "select", Options: []string{"regulatory", "risk", "performance", "value_prop", "new_product"}, Required: true},
			},
			NextStep:   "continue",
			IsComplete: false,
		}, nil
	}

	return &intakeResponse, nil
}

func (a *AgentService) continueIntake(ctx context.Context, req IntakeRequest) (*IntakeResponse, error) {
	// Contar respuestas totales del usuario (incluyendo la actual)
	questionCount := 1 // La respuesta actual cuenta como 1
	if req.Context != nil {
		if history, ok := req.Context["conversation_history"].([]interface{}); ok {
			questionCount += len(history) // Sumar respuestas previas
		}
	}

	// DEBUG: Log del conteo de preguntas
	fmt.Printf("DEBUG: questionCount = %d\n", questionCount)

	// Solo manejar respuestas de confirmaci√≥n si estamos en modo confirmaci√≥n
	// Modo confirmaci√≥n se detecta por la existencia de "awaiting_confirmation" en el contexto
	userInput := strings.ToLower(strings.TrimSpace(req.UserInput))
	fmt.Printf("DEBUG: userInput = '%s'\n", userInput)

	// Verificar si estamos en modo confirmaci√≥n
	awaitingConfirmation := false
	if req.Context != nil {
		if val, exists := req.Context["awaiting_confirmation"]; exists {
			awaitingConfirmation = val.(bool)
		}
	}

	fmt.Printf("DEBUG: awaiting_confirmation = %v\n", awaitingConfirmation)

	// Solo verificar respuestas de confirmaci√≥n si estamos esper√°ndolas
	if awaitingConfirmation && a.isConfirmationResponse(userInput) {
		fmt.Printf("DEBUG: Detectada respuesta de confirmaci√≥n v√°lida\n")
		return a.handleConfirmationResponse(ctx, req, userInput)
	}

	// L√≠mite ABSOLUTO: m√°ximo 3 respuestas - NO puede ser sobrescrito (cambiado para pruebas r√°pidas)
	fmt.Printf("DEBUG: Evaluando l√≠mite - questionCount = %d\n", questionCount)
	if questionCount >= 3 {
		fmt.Printf("DEBUG: L√≠mite alcanzado, generando confirmaci√≥n\n")
		return a.generateConfirmationSummary(ctx, req)
	}
	fmt.Printf("DEBUG: Continuando con preguntas\n")

	// Evaluaci√≥n inteligente SOLO si tenemos menos de 3 preguntas
	// Esto evita que la evaluaci√≥n inteligente sobrescriba el l√≠mite absoluto
	if questionCount < 3 {
		hasEnoughInfo, shouldConfirm := a.evaluateCompleteness(req.Initiative, req.Context, questionCount)
		if hasEnoughInfo || shouldConfirm {
			return a.generateConfirmationSummary(ctx, req)
		}
	}

	systemPrompt := `Eres un Product Manager senior especializado en fintech, trabajando para Pomelo - una empresa l√≠der de infraestructura de pagos en Am√©rica Latina. Tu trabajo es guiar la creaci√≥n de iniciativas de negocio tecnol√≥gicas con un enfoque experto en el ecosistema fintech.

## CONTEXTO DE NEGOCIO - POMELO
Pomelo es una plataforma de infraestructura de pagos que ofrece:
- Procesamiento de pagos y transacciones
- Emisi√≥n y manejo de tarjetas (d√©bito/cr√©dito)
- Tokenizaci√≥n y seguridad de pagos
- APIs para integration con bancos y fintechs
- Soluciones core banking y BIN sponsorship
- Prevenci√≥n de fraude y gesti√≥n de riesgos

## MERCADOS Y CLIENTES
**Pa√≠ses objetivo**: Brasil (25 puntos), M√©xico (20 puntos), Argentina (15 puntos), Colombia (12 puntos), Chile (10 puntos), Per√∫ (8 puntos)

**Tipos de Cliente**:
- Top Issuers: Bancos principales con >1M tarjetas
- Major: Bancos tier 1 con 500K-1M tarjetas
- Medium: Bancos tier 2 con 100K-500K tarjetas
- Small: Bancos tier 3 con <100K tarjetas
- Startups: Fintechs emergentes con productos innovadores

## CATEGOR√çAS DE INICIATIVAS
1. **Regulatory (Mandatos)**: Compliance, regulaciones, normativas PCI-DSS, LGPD
2. **Risk (Gesti√≥n de Riesgo)**: Fraude, lavado de dinero, riesgo operacional, ciberseguridad
3. **Performance (Rendimiento)**: Latencia, throughput, disponibilidad, optimizaci√≥n de APIs
4. **Value Prop (Propuesta de Valor)**: Nuevas features, mejoras UX, diferenciaci√≥n competitiva
5. **New Product (Nuevo Producto)**: Productos completamente nuevos, expansi√≥n de mercado

## VERTICALES T√âCNICOS
- **Processing**: Procesamiento de transacciones, clearing & settlement
- **Core Banking**: Sistemas core, gesti√≥n de cuentas, balances
- **BIN Sponsorship**: Emisi√≥n de tarjetas, programa management
- **Card Management**: Lifecycle de tarjetas, activaci√≥n, bloqueos
- **Tokenization**: Tokenizaci√≥n PCI, vault de datos sensibles
- **Fraud Prevention**: Machine learning para detecci√≥n, reglas de negocio
- **Platform & APIs**: Infraestructura, microservicios, integrations

## METHODOLOGY & SCORING
**Criterios de Scoring**:
- Impacto Econ√≥mico: Significativo (ingresos >$1M), Moderado ($100K-1M), Bajo (<$100K)
- Nivel de Innovaci√≥n: Disruptivo (cambia el mercado), Incremental (mejora), Paridad (catch-up)
- Riesgo Sist√©mico: Blocker (cr√≠tico), High (alto), Medium (medio), Low (bajo)
- Esfuerzo: Semanas de desarrollo estimadas
- Confianza: Nivel de certeza en estimaciones (1-10)

## TU ROL COMO EXPERTO
1. **Contexto Experto**: Usa terminolog√≠a fintech precisa y haz preguntas que demuestren conocimiento profundo del dominio
2. **Priorizaci√≥n Inteligente**: Identifica iniciativas que realmente impactan KPIs de negocio (TPV, take rate, time-to-market, NPS)
3. **Riesgos T√©cnicos**: Considera complejidad de integraci√≥n, dependencias regulatorias, impacto en legacy systems
4. **Competitive Landscape**: Reconoce trends del mercado (Open Banking, PIX, instant payments, embedded finance)

## REGLAS DE CONVERSACI√ìN
1. Saluda profesionalmente y pregunta sobre el desaf√≠o de negocio espec√≠fico
2. Haz preguntas inteligentes que demuestren expertise fintech
3. Extrae informaci√≥n estructurada autom√°ticamente
4. Considera el contexto regional (ej: PIX en Brasil, CoDi en M√©xico)
5. Valida feasibility t√©cnica y regulatory compliance

## EXTRACCI√ìN ESTRUCTURADA
Extrae autom√°ticamente:
- title: T√≠tulo ejecutivo profesional
- summary: Resumen ejecutivo de 1-2 oraciones
- category: regulatory|risk|performance|value_prop|new_product
- vertical: processing|core|bin-sponsor|card-mgmt|tokenization|fraud|platform
- countries: Array con c√≥digos ["brazil","mexico","argentina","colombia","chile","peru"]
- client_type: top_issuer|major|medium|small|startup
- economic_impact_type: significant|moderate|low|hard_to_quantify
- innovation_level: disruptive|incremental|parity
- systemic_risk: blocker|high|medium|low
- problem_description: Descripci√≥n t√©cnica del problema
- business_case: Justificaci√≥n de negocio con m√©tricas
- client_segment: Perfil detallado del cliente objetivo

## FORMATO DE RESPUESTA JSON
{
  "questions": [
    {
      "id": "unique_id",
      "text": "Pregunta estrat√©gica en espa√±ol",
      "type": "text|select|multiselect|boolean",
      "options": ["opci√≥n1", "opci√≥n2"],
      "required": true|false
    }
  ],
  "extracted_data": {
    "title": "t√≠tulo ejecutivo",
    "summary": "resumen ejecutivo",
    "category": "performance",
    "vertical": "processing",
    "countries": ["brazil"],
    "client_type": "major",
    "economic_impact_type": "significant",
    "innovation_level": "incremental",
    "systemic_risk": "medium",
    "problem_description": "descripci√≥n t√©cnica",
    "business_case": "justificaci√≥n con ROI",
    "client_segment": "perfil del cliente"
  },
  "next_step": "continue",
  "is_complete": false
}

## EJEMPLOS CONTEXTUALIZADOS
- Input: "Necesito reducir la latencia de autorizaci√≥n"
  ‚Üí Pregunta: "¬øCu√°l es la latencia actual vs target? ¬øImpacta m√°s a transacciones e-commerce o POS?"
  ‚Üí Extrae: category="performance", vertical="processing"

- Input: "Compliance con nueva regulaci√≥n brasile√±a"
  ‚Üí Pregunta: "¬øSe refiere a Resolu√ß√£o BCB, PIX regulations o LGPD? ¬øQu√© deadline tenemos?"
  ‚Üí Extrae: category="regulatory", countries=["brazil"]

- Input: "Producto para startups fintech"
  ‚Üí Pregunta: "¬øQu√© funcionalidades core necesitan? ¬øEmisi√≥n, processing o APIs de onboarding?"
  ‚Üí Extrae: client_type="startup", category="new_product"`

	// Preparar contexto completo incluyendo historial de conversaci√≥n
	contextInfo := fmt.Sprintf("Input actual del usuario: %s", req.UserInput)
	contextInfo += fmt.Sprintf("\nN√∫mero de preguntas ya realizadas: %d", questionCount)

	// Incluir TODA la conversaci√≥n previa
	if req.Context != nil {
		if history, ok := req.Context["conversation_history"].([]interface{}); ok && len(history) > 0 {
			contextInfo += "\n\nHISTORIAL COMPLETO DE LA CONVERSACI√ìN:\n"
			for i, entry := range history {
				if entryMap, ok := entry.(map[string]interface{}); ok {
					if user, exists := entryMap["user"]; exists {
						contextInfo += fmt.Sprintf("%d. Usuario: %v\n", i+1, user)
					}
				}
			}
			contextInfo += "\nIMPORTANTE: NO repitas preguntas que ya fueron respondidas en el historial.\n"
		}
	}

	if req.Initiative != nil {
		initiativeJSON, _ := json.Marshal(req.Initiative)
		contextInfo += fmt.Sprintf("\nDatos extra√≠dos de la iniciativa hasta ahora: %s", string(initiativeJSON))
	}
	if req.Context != nil {
		// Solo incluir campos que no sean conversation_history para evitar duplicaci√≥n
		contextCopy := make(map[string]interface{})
		for k, v := range req.Context {
			if k != "conversation_history" {
				contextCopy[k] = v
			}
		}
		if len(contextCopy) > 0 {
			contextJSON, _ := json.Marshal(contextCopy)
			contextInfo += fmt.Sprintf("\nContexto de negocio recopilado: %s", string(contextJSON))
		}
	}

	response, err := a.callOpenAI(ctx, systemPrompt, contextInfo)
	if err != nil {
		return nil, fmt.Errorf("error calling OpenAI: %w", err)
	}

	// Parse JSON response
	var intakeResponse IntakeResponse
	if err := json.Unmarshal([]byte(response), &intakeResponse); err != nil {
		// Fallback to contextual questions based on user input
		return a.generateContextualFallback(req.UserInput, req.Context), nil
	}

	// Check if the AI response makes sense for the user input
	lowerInput := strings.ToLower(req.UserInput)
	if strings.Contains(lowerInput, "hola") || strings.Contains(lowerInput, "buenos") || strings.Contains(lowerInput, "buenas") {
		// If user said hello but AI asked about countries/categories, use fallback
		if strings.Contains(intakeResponse.Questions[0].Text, "pa√≠s") || strings.Contains(intakeResponse.Questions[0].Text, "categor√≠a") {
			return a.generateContextualFallback(req.UserInput, req.Context), nil
		}
	}

	return &intakeResponse, nil
}

// shouldCompleteIntake verifica si tenemos suficiente informaci√≥n para completar el intake
func (a *AgentService) shouldCompleteIntake(initiative *domain.Initiative, context map[string]interface{}) bool {
	// Verificar campos obligatorios de la iniciativa
	if initiative == nil {
		return false
	}

	// Campos obligatorios del modelo Initiative
	if initiative.Title == "" || initiative.Summary == "" {
		return false
	}
	if initiative.Category == "" || initiative.Vertical == "" {
		return false
	}
	if len(initiative.Countries) == 0 || initiative.ClientType == "" {
		return false
	}

	// Verificar que tenemos informaci√≥n m√≠nima del contexto
	if context == nil {
		return false
	}

	// Verificar campos cr√≠ticos del contexto
	requiredContextFields := []string{
		"problem_description",
		"business_case",
		"economic_impact",
		"client_segment",
		"urgency",
	}

	completedFields := 0
	for _, field := range requiredContextFields {
		if value, exists := context[field]; exists {
			if str, ok := value.(string); ok && len(strings.TrimSpace(str)) > 0 {
				completedFields++
			}
		}
	}

	// Requerimos al menos 4 de 5 campos cr√≠ticos completados
	return completedFields >= 4
}

// evaluateCompleteness eval√∫a inteligentemente si tenemos suficiente informaci√≥n
func (a *AgentService) evaluateCompleteness(initiative *domain.Initiative, context map[string]interface{}, questionCount int) (bool, bool) {
	// Evaluar calidad de la informaci√≥n recopilada
	hasTitle := initiative != nil && initiative.Title != ""
	hasSummary := initiative != nil && initiative.Summary != ""
	hasCategory := initiative != nil && initiative.Category != ""
	hasVertical := initiative != nil && initiative.Vertical != ""
	hasCountries := initiative != nil && len(initiative.Countries) > 0
	hasClientType := initiative != nil && initiative.ClientType != ""

	// Campos cr√≠ticos del contexto
	contextFields := 0
	if context != nil {
		criticalFields := []string{"problem_description", "business_case", "economic_impact", "client_segment"}
		for _, field := range criticalFields {
			if value, exists := context[field]; exists {
				if str, ok := value.(string); ok && len(strings.TrimSpace(str)) > 0 {
					contextFields++
				}
			}
		}
	}

	// Criterios de evaluaci√≥n inteligente
	basicInfoComplete := hasTitle && hasSummary && hasCategory && hasVertical
	businessInfoComplete := hasCountries && hasClientType && contextFields >= 3

	// Despu√©s de 2 preguntas, evaluar si vale la pena mostrar resumen
	// Cambiado de 8 a 2 para pruebas r√°pidas
	if questionCount >= 2 {
		// Si tenemos info b√°sica completa, ofrecer resumen aunque falten detalles
		if basicInfoComplete && contextFields >= 3 {
			return false, true // No completo, pero ofrecer confirmaci√≥n
		}
	}

	// Si tenemos toda la info esencial, completar
	if basicInfoComplete && businessInfoComplete {
		return true, true // Completo y ofrecer confirmaci√≥n
	}

	return false, false // Continuar con preguntas
}

// generateConfirmationSummary genera el resumen de confirmaci√≥n con opciones para el usuario
func (a *AgentService) generateConfirmationSummary(ctx context.Context, req IntakeRequest) (*IntakeResponse, error) {
	// Preparar contexto completo incluyendo historial de conversaci√≥n
	contextInfo := fmt.Sprintf("Input actual del usuario: %s", req.UserInput)

	// Incluir TODA la conversaci√≥n previa
	if req.Context != nil {
		if history, ok := req.Context["conversation_history"].([]interface{}); ok && len(history) > 0 {
			contextInfo += "\n\nHISTORIAL COMPLETO DE LA CONVERSACI√ìN:\n"
			for i, entry := range history {
				if entryMap, ok := entry.(map[string]interface{}); ok {
					if user, exists := entryMap["user"]; exists {
						contextInfo += fmt.Sprintf("%d. Usuario: %v\n", i+1, user)
					}
				}
			}
		}

		// Incluir contexto adicional
		contextJSON, _ := json.Marshal(req.Context)
		contextInfo += fmt.Sprintf("\nContexto recopilado: %s\n", string(contextJSON))
	}

	if req.Initiative != nil {
		initiativeJSON, _ := json.Marshal(req.Initiative)
		contextInfo += fmt.Sprintf("Datos de iniciativa: %s\n", string(initiativeJSON))
	}

	// Crear prompt espec√≠fico para generar resumen ejecutivo
	prompt := fmt.Sprintf(`%s

INSTRUCCIONES PARA GENERAR RESUMEN EJECUTIVO:
Bas√°ndote en toda la conversaci√≥n anterior, genera un resumen ejecutivo profesional y completo que incluya:

1. Un resumen de las respuestas espec√≠ficas del usuario
2. Informaci√≥n extra√≠da y estructurada sobre la iniciativa
3. Un formato de confirmaci√≥n que muestre claramente lo que entendiste

Debes devolver √öNICAMENTE un JSON con este formato:
{
  "confirmation_summary": "Resumen ejecutivo detallado en markdown que incluya toda la informaci√≥n de la conversaci√≥n",
  "extracted_data": {
    "title": "t√≠tulo inferido de la conversaci√≥n",
    "summary": "resumen t√©cnico de 1-2 oraciones",
    "category": "regulatory|risk|performance|value_prop|new_product",
    "vertical": "processing|core|bin-sponsor|card-mgmt|tokenization|fraud|platform",
    "countries": ["array de pa√≠ses mencionados"],
    "client_type": "tipo de cliente inferido",
    "economic_impact_type": "impacto econ√≥mico inferido",
    "problem_description": "descripci√≥n del problema basada en las respuestas",
    "business_case": "caso de negocio inferido",
    "client_segment": "segmento de cliente inferido"
  },
  "next_step": "confirm",
  "is_complete": true
}

IMPORTANTE: El confirmation_summary debe incluir espec√≠ficamente las respuestas que dio el usuario, no informaci√≥n gen√©rica.`, contextInfo)

	// Llamar al LLM
	response, err := a.callOpenAI(ctx, prompt, "")
	if err != nil {
		fmt.Printf("Error llamando LLM para generar resumen de confirmaci√≥n: %v\n", err)
		return nil, fmt.Errorf("failed to generate confirmation summary: %w", err)
	}

	// Parsear respuesta JSON
	var llmResponse struct {
		ConfirmationSummary string                 `json:"confirmation_summary"`
		ExtractedData       map[string]interface{} `json:"extracted_data"`
		NextStep            string                 `json:"next_step"`
		IsComplete          bool                   `json:"is_complete"`
	}

	if err := json.Unmarshal([]byte(response), &llmResponse); err != nil {
		fmt.Printf("Error parseando JSON del resumen de confirmaci√≥n: %v\n", err)
		return nil, fmt.Errorf("failed to parse LLM response for confirmation summary: %w", err)
	}

	return &IntakeResponse{
		Questions: []Question{
			{
				ID:       "confirmation",
				Text:     llmResponse.ConfirmationSummary + "\n\n**¬øQu√© desea hacer?**\n‚úÖ **'confirmar'** - Crear la iniciativa\n‚ûï **'continuar'** - Refinar m√°s detalles\n‚úèÔ∏è **'modificar'** - Cambiar informaci√≥n",
				Type:     "text",
				Required: false,
			},
		},
		ConfirmationSummary: llmResponse.ConfirmationSummary,
		ExtractedData:       llmResponse.ExtractedData,
		NextStep:            llmResponse.NextStep,
		IsComplete:          llmResponse.IsComplete,
		AwaitingConfirmation: true, // Marcar que estamos esperando confirmaci√≥n
	}, nil
}


// generateContextualFallback genera preguntas contextuales cuando falla el parsing del JSON
func (a *AgentService) generateContextualFallback(userInput string, context map[string]interface{}) *IntakeResponse {
	lowerInput := strings.ToLower(userInput)

	// Si es un saludo, responder de manera amigable
	if strings.Contains(lowerInput, "hola") || strings.Contains(lowerInput, "buenos") || strings.Contains(lowerInput, "buenas") {
		return &IntakeResponse{
			Questions: []Question{
				{ID: "greeting_followup", Text: "¬°Hola! Me alegra que quieras crear una nueva iniciativa. ¬øPodr√≠as contarme qu√© problema espec√≠fico te gustar√≠a resolver?", Type: "text", Required: true},
			},
			NextStep:   "continue",
			IsComplete: false,
		}
	}

	// Si menciona un pa√≠s espec√≠fico
	if strings.Contains(lowerInput, "argentina") || strings.Contains(lowerInput, "brasil") || strings.Contains(lowerInput, "m√©xico") || strings.Contains(lowerInput, "colombia") || strings.Contains(lowerInput, "chile") {
		return &IntakeResponse{
			Questions: []Question{
				{ID: "country_specific", Text: "Perfecto, veo que mencionas un pa√≠s espec√≠fico. ¬øPodr√≠as contarme m√°s detalles sobre la iniciativa que tienes en mente?", Type: "text", Required: true},
			},
			NextStep:   "continue",
			IsComplete: false,
		}
	}

	// Si menciona un problema o necesidad
	if strings.Contains(lowerInput, "problema") || strings.Contains(lowerInput, "necesito") || strings.Contains(lowerInput, "quiero") || strings.Contains(lowerInput, "mejorar") {
		return &IntakeResponse{
			Questions: []Question{
				{ID: "problem_details", Text: "Entiendo que tienes un problema espec√≠fico. ¬øPodr√≠as darme m√°s detalles sobre c√≥mo esto afecta a tus clientes o usuarios?", Type: "text", Required: true},
			},
			NextStep:   "continue",
			IsComplete: false,
		}
	}

	// Pregunta gen√©rica pero contextual
	return &IntakeResponse{
		Questions: []Question{
			{ID: "general_context", Text: "Interesante. ¬øPodr√≠as contarme m√°s sobre esta iniciativa? ¬øQu√© problema espec√≠fico est√°s tratando de resolver?", Type: "text", Required: true},
		},
		NextStep:   "continue",
		IsComplete: false,
	}
}

func (a *AgentService) validateIntake(ctx context.Context, req IntakeRequest) (*IntakeResponse, error) {
	systemPrompt := `Eres el Director de Producto Senior de Pomelo, l√≠der en infraestructura de pagos de LATAM. Tu funci√≥n es crear res√∫menes ejecutivos estrat√©gicos para el comit√© de priorizaci√≥n de iniciativas.

## CONTEXTO EMPRESARIAL POMELO
Pomelo es la infraestructura de pagos l√≠der en LATAM con:
- Presencia en Brasil, M√©xico, Argentina, Colombia, Chile
- Clientes: desde startups fintech hasta bancos Tier 1
- Stack completo: procesamiento, emisi√≥n, core banking, BIN sponsorship
- Vol√∫menes: $10B+ anuales procesados
- Foco en innovaci√≥n y compliance regulatoria

## TU ROL COMO DIRECTOR DE PRODUCTO
Generas res√∫menes ejecutivos que el C-Level y board usan para:
- Tomar decisiones de inversi√≥n y priorizaci√≥n
- Asignar recursos de engineering ($2M+ por iniciativa)
- Evaluar impacto competitivo y market timing
- Alinear roadmap con objetivos estrat√©gicos

## FORMATO DE RESUMEN EJECUTIVO
Crea un resumen profesional que incluya:

**üéØ OPORTUNIDAD ESTRAT√âGICA**
- Problema espec√≠fico del ecosistema fintech LATAM
- Gap competitivo vs players como Stone, PagSeguro, Mercado Pago
- Market size y revenue opportunity potencial

**üí∞ JUSTIFICACI√ìN DE NEGOCIO**
- ROI proyectado y timeline de recuperaci√≥n
- Impacto en m√©tricas clave (TPV, take rate, NPS, churn)
- Requisitos de inversi√≥n estimados (engineering, compliance, ops)

**üéØ ALCANCE Y COMPLEJIDAD**
- Verticales t√©cnicos involucrados (core, processing, fraud, etc.)
- Pa√≠ses/regulaciones afectadas (BCB, CNBV, etc.)
- Tipo de clientes beneficiados (tier 1, startups, etc.)

**‚ö° URGENCIA Y RIESGOS**
- Timeline cr√≠tico (deadlines regulatorios, launches competidores)
- Riesgos t√©cnicos, de compliance o de mercado
- Dependencias con otros equipos/iniciativas

## EJEMPLOS DE TERMINOLOG√çA FINTECH
- TPV (Total Payment Volume), take rate, interchange
- Acquiring, issuing, tokenization, 3DS authentication
- PCI compliance, fraud scoring, risk management
- Open banking, PIX, instant payments, BNPL
- Card-on-file, recurring billing, marketplace facilitation

Redacta en espa√±ol con terminolog√≠a t√©cnica precisa y enfoque en business impact cuantificable. El resumen debe mostrar por qu√© esta iniciativa merece recursos vs otras 50+ en el backlog.`

	// Prepare all collected information
	contextInfo := fmt.Sprintf("Input del usuario: %s", req.UserInput)
	if req.Initiative != nil {
		initiativeJSON, _ := json.Marshal(req.Initiative)
		contextInfo += fmt.Sprintf("\nInformaci√≥n de la iniciativa: %s", string(initiativeJSON))
	}
	if req.Context != nil {
		contextJSON, _ := json.Marshal(req.Context)
		contextInfo += fmt.Sprintf("\nContexto adicional: %s", string(contextJSON))
	}

	summary, err := a.callOpenAI(ctx, systemPrompt, contextInfo)
	if err != nil {
		fmt.Printf("Error llamando LLM para generar resumen ejecutivo: %v\n", err)
		return nil, fmt.Errorf("failed to generate executive summary: %w", err)
	}

	return &IntakeResponse{
		ExecutiveSummary: summary,
		NextStep:         "complete",
		IsComplete:       true,
	}, nil
}


// Estimation intervention implementation
func (a *AgentService) EstimationIntervention(ctx context.Context, req EstimationRequest) (*EstimationResponse, error) {
	switch req.Step {
	case "start":
		return a.startEstimation(ctx, req)
	case "continue":
		return a.continueEstimation(ctx, req)
	case "validate":
		return a.validateEstimation(ctx, req)
	default:
		return nil, fmt.Errorf("unknown estimation step: %s", req.Step)
	}
}

func (a *AgentService) startEstimation(ctx context.Context, req EstimationRequest) (*EstimationResponse, error) {
	systemPrompt := `Eres un experto t√©cnico que ayuda a estimar el esfuerzo de iniciativas de software/tecnolog√≠a. Genera preguntas inteligentes para obtener una estimaci√≥n precisa.

IMPORTANTE: Responde SOLO con JSON v√°lido siguiendo este formato exacto:
{
  "questions": [
    {
      "id": "unique_id",
      "text": "Pregunta en espa√±ol",
      "type": "text|select|number",
      "options": ["opci√≥n1", "opci√≥n2"],
      "required": true|false
    }
  ],
  "next_step": "continue",
  "is_complete": false
}

Niveles de riesgo disponibles: blocker, high, medium, low
Genera preguntas sobre esfuerzo, confianza, dependencias y complejidad t√©cnica.`

	userPrompt := fmt.Sprintf("Iniciativa a estimar: %s\nInput del usuario: %s", req.Initiative.Title, req.UserInput)

	response, err := a.callOpenAI(ctx, systemPrompt, userPrompt)
	if err != nil {
		return nil, fmt.Errorf("error calling OpenAI: %w", err)
	}

	var estimationResponse EstimationResponse
	if err := json.Unmarshal([]byte(response), &estimationResponse); err != nil {
		// Fallback
		return &EstimationResponse{
			Questions: []Question{
				{ID: "effort_weeks", Text: "¬øCu√°ntas semanas tomar√° implementar?", Type: "number", Required: true},
				{ID: "confidence_level", Text: "¬øCu√°l es tu confianza (1-10)?", Type: "number", Required: true},
			},
			NextStep:   "continue",
			IsComplete: false,
		}, nil
	}

	return &estimationResponse, nil
}

func (a *AgentService) continueEstimation(ctx context.Context, req EstimationRequest) (*EstimationResponse, error) {
	systemPrompt := `Genera preguntas de seguimiento para completar la estimaci√≥n t√©cnica bas√°ndote en las respuestas anteriores.

IMPORTANTE: Responde SOLO con JSON v√°lido siguiendo este formato exacto:
{
  "questions": [
    {
      "id": "unique_id",
      "text": "Pregunta en espa√±ol",
      "type": "text|select|number",
      "options": ["opci√≥n1", "opci√≥n2"],
      "required": true|false
    }
  ],
  "next_step": "validate",
  "is_complete": false
}

Niveles de riesgo: blocker, high, medium, low
Enf√≥cate en riesgos t√©cnicos, dependencias y factores que afecten la estimaci√≥n.`

	contextInfo := fmt.Sprintf("Iniciativa: %s\nInput: %s", req.Initiative.Title, req.UserInput)

	response, err := a.callOpenAI(ctx, systemPrompt, contextInfo)
	if err != nil {
		return nil, fmt.Errorf("error calling OpenAI: %w", err)
	}

	var estimationResponse EstimationResponse
	if err := json.Unmarshal([]byte(response), &estimationResponse); err != nil {
		// Fallback
		return &EstimationResponse{
			Questions: []Question{
				{ID: "technical_risks", Text: "¬øQu√© riesgos t√©cnicos anticipas?", Type: "text", Required: false},
				{ID: "systemic_risk", Text: "¬øNivel de riesgo sist√©mico?", Type: "select", Options: []string{"blocker", "high", "medium", "low"}, Required: true},
			},
			NextStep:   "validate",
			IsComplete: false,
		}, nil
	}

	return &estimationResponse, nil
}

func (a *AgentService) validateEstimation(ctx context.Context, req EstimationRequest) (*EstimationResponse, error) {
	systemPrompt := `Bas√°ndote en toda la informaci√≥n recopilada, genera un an√°lisis final de la estimaci√≥n t√©cnica. Proporciona insights sobre la estimaci√≥n, riesgos identificados y recomendaciones.

Responde en espa√±ol de forma profesional y estructurada.`

	contextInfo := fmt.Sprintf("Iniciativa: %s\nInput: %s", req.Initiative.Title, req.UserInput)
	if req.Initiative != nil {
		estimationJSON, _ := json.Marshal(req.Initiative.TechnicalEstimation)
		contextInfo += fmt.Sprintf("\nEstimaci√≥n t√©cnica: %s", string(estimationJSON))
	}

	_, err := a.callOpenAI(ctx, systemPrompt, contextInfo)
	if err != nil {
		// Log error but continue with the response
		fmt.Printf("OpenAI call failed for validation: %v\n", err)
	}

	return &EstimationResponse{
		Estimation: &req.Initiative.TechnicalEstimation,
		NextStep:   "complete",
		IsComplete: true,
	}, nil
}

// Scoring intervention implementation
func (a *AgentService) ScoringIntervention(ctx context.Context, req ScoringRequest) (*ScoringResponse, error) {
	scoreBreakdown, err := a.scoringService.CalculateScore(req.Initiative)
	if err != nil {
		return nil, fmt.Errorf("failed to calculate score: %w", err)
	}

	return &ScoringResponse{
		ScoreBreakdown: scoreBreakdown,
	}, nil
}

// isConfirmationResponse verifica si el input del usuario es una respuesta a las opciones de confirmaci√≥n
func (a *AgentService) isConfirmationResponse(userInput string) bool {
	// Detectar respuestas de confirmaci√≥n comunes - SOLO palabras completas o contextos espec√≠ficos
	lowerInput := strings.ToLower(strings.TrimSpace(userInput))

	// Patrones exactos de confirmaci√≥n
	exactConfirmations := []string{
		"confirm", "confirmar", "si", "s√≠", "yes", "crear", "finalizar",
		"continuar", "refinar", "seguir", "modificar", "cambiar", "editar", "corregir",
		"‚úÖ", "‚ûï", "‚úèÔ∏è",
	}

	// Buscar palabras exactas (no como substring)
	words := strings.Fields(lowerInput)
	for _, word := range words {
		for _, action := range exactConfirmations {
			if word == action {
				return true
			}
		}
	}

	// Frases espec√≠ficas de confirmaci√≥n
	confirmPhrases := []string{
		"crear la iniciativa", "confirmar y crear", "quiero crear",
		"continuar con m√°s preguntas", "seguir preguntando", "m√°s detalles",
		"modificar algo", "cambiar informaci√≥n", "editar datos",
	}

	for _, phrase := range confirmPhrases {
		if strings.Contains(lowerInput, phrase) {
			return true
		}
	}

	return false
}

// handleConfirmationResponse maneja las respuestas del usuario a las opciones de confirmaci√≥n
func (a *AgentService) handleConfirmationResponse(ctx context.Context, req IntakeRequest, userInput string) (*IntakeResponse, error) {
	// Detectar el tipo de acci√≥n seleccionada
	if strings.Contains(userInput, "confirm") || strings.Contains(userInput, "confirmar") ||
		strings.Contains(userInput, "crear") || strings.Contains(userInput, "finalizar") ||
		strings.Contains(userInput, "‚úÖ") || strings.Contains(userInput, "si") || strings.Contains(userInput, "s√≠") {
		// Usuario quiere confirmar y crear la iniciativa
		return &IntakeResponse{
			NextStep:   "validate",
			IsComplete: false, // Ir a validaci√≥n final
		}, nil
	}

	if strings.Contains(userInput, "continue") || strings.Contains(userInput, "continuar") ||
		strings.Contains(userInput, "refinar") || strings.Contains(userInput, "m√°s") ||
		strings.Contains(userInput, "‚ûï") || strings.Contains(userInput, "seguir") {
		// Usuario quiere continuar refinando
		return &IntakeResponse{
			Questions: []Question{
				{
					ID:       "continue_refinement",
					Text:     "¬øQu√© aspecto espec√≠fico te gustar√≠a refinar o agregar m√°s detalles?",
					Type:     "text",
					Required: true,
				},
			},
			NextStep:   "continue",
			IsComplete: false,
		}, nil
	}

	if strings.Contains(userInput, "modify") || strings.Contains(userInput, "modificar") ||
		strings.Contains(userInput, "cambiar") || strings.Contains(userInput, "editar") ||
		strings.Contains(userInput, "corregir") || strings.Contains(userInput, "‚úèÔ∏è") {
		// Usuario quiere modificar algo
		return &IntakeResponse{
			Questions: []Question{
				{
					ID:       "modification_field",
					Text:     "¬øQu√© informaci√≥n espec√≠fica te gustar√≠a modificar? (t√≠tulo, categor√≠a, descripci√≥n, etc.)",
					Type:     "text",
					Required: true,
				},
			},
			NextStep:   "continue",
			IsComplete: false,
		}, nil
	}

	// Si no podemos detectar la acci√≥n espec√≠fica, preguntar por clarificaci√≥n
	return &IntakeResponse{
		Questions: []Question{
			{
				ID:       "clarify_action",
				Text:     "No estoy seguro de qu√© acci√≥n quieres realizar. ¬øPodr√≠as especificar si quieres: 1) Confirmar y crear la iniciativa, 2) Continuar agregando detalles, o 3) Modificar algo espec√≠fico?",
				Type:     "text",
				Required: true,
			},
		},
		NextStep:   "continue",
		IsComplete: false,
	}, nil
}

// ScoringService interface
type ScoringService interface {
	CalculateScore(initiative *domain.Initiative) (*domain.ScoreBreakdown, error)
}
